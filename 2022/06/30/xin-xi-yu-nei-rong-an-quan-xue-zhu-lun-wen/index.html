<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Hexo">
    <meta name="description" content="无关键点的细粒度头部姿态估计摘 要   人的头部姿态估计是一个关键问题，有大量的应用，如帮助注视估计，建模注意力，拟合3D模型的视频和执行脸对齐等。传统的头部姿态计算方法是通过估计目标面部的一些关键点，利用平均的头部模型求解二维到三维的对应">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    

    <title>Hexo</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">

    <script src="/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 6.2.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Hexo</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Hexo</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			留言板
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/blinkfox/hexo-theme-matery" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/blinkfox/hexo-theme-matery" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/0.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title"></h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        padding: 35px 0 15px 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        padding-bottom: 30px;
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                          <div class="article-tag">
                            <span class="chip bg-color">无标签</span>
                          </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2022-06-30
                </div>
                

                

                

                

                
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="/libs/prism/prism.min.css">
        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="无关键点的细粒度头部姿态估计"><a href="#无关键点的细粒度头部姿态估计" class="headerlink" title="无关键点的细粒度头部姿态估计"></a>无关键点的细粒度头部姿态估计</h1><p>摘 要   人的头部姿态估计是一个关键问题，有大量的应用，如帮助注视估计，建模注意力，拟合3D模型的视频和执行脸对齐等。传统的头部姿态计算方法是通过估计目标面部的一些关键点，利用平均的头部模型求解二维到三维的对应问题。我们认为这是一个脆弱的方法，因为它完全依赖于地标检测性能，额外的头部模型和一个特别的拟合步骤。我们提出了一种优雅而稳健的方式来确定姿态，方法是在300W-LP(一个大型综合扩展数据集)上训练一个多重损失的卷积神经网络，通过联合binned姿态分类和回归，直接从图像强度预测固有欧拉角(偏航、俯仰和滚转)。我们对常见的野外姿态基准数据集进行了实证测试，显示了最先进的结果。此外，我们在通常用于使用深度进行姿态估计的数据集上测试我们的方法，并开始缩小与最先进的深度姿态方法的差距。</p>
<p>关键词   细粒度；头部姿态估计；多重损失；卷积神经网络；欧拉角；</p>
<p>Fine-Grained Head Pose Estimation Without Keypoints</p>
<p>Youle Wang</p>
<p>Department of cyber engineering, Xidian University</p>
<p><strong>Abstract</strong>  Estimating the head pose of a person is a crucial problem that has a large amount of applications such as aiding in gaze estimation, modeling attention, fitting 3D models to video and performing face alignment. Traditionally head pose is computed by estimating some keypoints from the target face and solving the 2D to 3D correspondence problem with a mean human head model. We argue that this is a fragile method because it relies entirely on landmark detection performance, the extraneous head model and an ad-hoc fitting step. We present an elegant and robust way to determine pose by training a multi-loss convolutional neural network on 300W-LP, a large synthetically expanded dataset, to predict intrinsic Euler angles (yaw, pitch and roll) directly from image intensities through joint binned pose classification and regression. We present empirical tests on common in-the-wild pose benchmark datasets which show state-of-the-art results. Additionally we test our method on a dataset usually used for pose estimation using depth and start to close the gap with state-of-the-art depth pose methods. </p>
<p><strong>Key words</strong>   Fine-Grained；Head Pose Estimation；multi-loss；convolutional neural network；Euler angles；</p>
<h1 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1. 介绍"></a>1. 介绍</h1><p>在过去的25年里，头部姿态估计和面部表情跟踪的相关问题在推动非刚性配准和3D重建的视觉技术以及实现操纵多媒体内容和与用户交互的新方法方面发挥了重要作用。从历史上看，有几种主要的面部建模方法，其中两种主要方法是区分/基于地标的方法[26,29]和参数化外观模型(PAMs)<a href="%E5%8F%82%E8%A7%81%5B30%5D%E8%BF%9B%E8%A1%8C%E6%9B%B4%E5%A4%9A%E7%9A%84%E8%AE%A8%E8%AE%BA">4,15</a>。近年来，利用现代深度学习工具[2,35,14]直接提取二维面部关键点的方法因其灵活性成为面部表情分析的主流方法以及对遮挡和极端姿态变化的鲁棒性。基于关键点的面部表情分析的副产品是，通过建立关键点和3D头部模型之间的对应关系并进行对齐，可以恢复头部的3D姿态。然而，在某些应用中，头部姿势可能是所有需要估计的。在这种情况下，基于关键点的方法仍然是最好的方法吗?使用现代深度学习工具还没有彻底解决这个问题，这是本文试图填补的一个文献空白。</p>
<p>在需要精确头部姿态估计的应用中，一个常见的解决方案是利用RGBD(深度)相机。它们可以非常准确，但也有一些限制:首先，由于它们使用主动传感，它们很难在户外和不受控制的环境情况下使用，由于主动照明可以被阳光或环境光淹没。其次，深度相机比RGB更耗电，导致在移动应用中存在严重的电池寿命问题，而且它们普遍不太流行。第三，RGBD的数据速率比RGB高，增加了存储和数据传输时间。因此，对于自动驾驶中的行人跟踪和安全监测、计算机图形学、驾驶员警觉性监测、通过视频理解社交场景等领域的广泛应用，仍然需要一种基于rgb的快速可靠的3D头部姿态估计解决方案。</p>
<p>我们工作的主要贡献如下:</p>
<p>•提出一种从图像强度直接预测头部姿态欧拉角的方法，使用多损失网络，每个角度都有损失，每个损失有两个分量:姿态分类和回归分量。我们在多个数据集的单帧姿态估计方面优于已发布的方法。</p>
<p>•通过在大型合成数据集上训练我们的模型，并在几个测试数据集上获得良好的结果，展示了我们的模型的泛化能力。</p>
<p>•介绍关于网络卷积架构的消融研究，以及我们损失函数的多个组成部分。</p>
<p>•详细研究了2D地标法的姿态精度，以及该方法的细节弱点，我们采用的基于外观的方法解决了这些弱点。</p>
<p>•研究不同方法下低分辨率对位姿估计的影响。我们表明，我们的方法结合数据增强是有效的，以解决有趣的问题，头部姿态估计低分辨率的图像。</p>
<h1 id="2-相关工作"><a href="#2-相关工作" class="headerlink" title="2. 相关工作"></a>2. 相关工作</h1><p>人体头部姿态估计是计算机视觉研究的一个重要课题，其研究方法多种多样。在经典文献中，我们可以辨别外观模板模型(Appearance Template Models)，它试图将测试图像与一组姿势样本进行比较[17,27,28]。当正面人脸检测[18,23]的成功率越来越高时，检测器阵列曾经是一种流行的方法，其想法是训练多个人脸检测器来适应不同的头部姿势[9,34]。</p>
<p>最近，人脸地标探测器已经变得非常精确[2,35,14]，在姿态估计任务中很受欢迎。</p>
<p>最近，利用神经网络估计头部姿态的工作也得到了发展。[19]对AFLW数据集上使用回归损失训练的相对较浅网络进行了深入研究。在开普勒[14]中，作者提出了一种改进的GoogleNet架构，它可以预测面部关键点和联合姿势。他们使用来自AFLW数据集的粗姿态监督来改进地标检测。有两部作品致力于建立一个网络来完成与面部分析有关的各种预测任务。Hyperface[20]是一个CNN，开始检测面孔，确定性别，找到地标和估计头部姿势一次。它使用基于R-CNN[7]的方法和改进的AlexNet架构，融合中间卷积层输出，并添加单独的全连接网络来预测每个子任务。All-InOne人脸分析卷积神经网络[21]在原有预测任务的基础上增加了微笑、年龄估计和人脸识别。我们将我们的结果与所有这些工作进行比较。</p>
<p>Chang等人，[3]也支持无地标头部姿态估计。他们使用简单的CNN回归3D头部姿势，并专注于使用预测的头部姿势的面部对齐。</p>
<p>他们证明了他们的方法的成功，通过使用他们的面部对齐管道提高面部识别的准确性。他们不直接评估头部姿态估计结果。这与我们的工作不同，因为我们直接评估和比较我们的头部姿势结果广泛的注释数据集。</p>
<h1 id="3-方法"><a href="#3-方法" class="headerlink" title="3.方法"></a>3.方法</h1><p>在本节中，我们描述了直接从图像强度使用深度网络估计头部姿态的优势，并认为它应该优先于地标-姿态方法。我们解释了在更大的合成300W-LP [35]数据集上训练时，如何使用组合分类和回归来提高性能。我们还将讨论关于数据增强、训练和测试数据集的关键见解，以及如何提高低分辨率图像的性能。</p>
<h2 id="3-1-深度学习在头部姿态估计中的优势"><a href="#3-1-深度学习在头部姿态估计中的优势" class="headerlink" title="3.1. 深度学习在头部姿态估计中的优势"></a>3.1. 深度学习在头部姿态估计中的优势</h2><p>尽管对读者来说，经过仔细的训练，深度网络可以准确地预测图1，这似乎是显而易见的。使用我们提出的方法在困难场景下的姿态检测示例。蓝色轴指向脸的前方，绿色轴指向下方，红色轴指向侧面。彩色观看效果最佳。</p>
<p><img src="https://s2.loli.net/2022/06/30/6q3ucsvzW4Hmr8L.gif" alt="img"></p>
<p>图1</p>
<p>该方法尚未得到广泛的研究，也不常用于头部姿态估计任务。</p>
<p>相反，如果需要非常精确的头部姿势，则安装深度摄像头，如果没有深度镜头存在，则检测地标并恢复姿势。在这项工作中，我们证明了在大型合成数据集上训练的网络，根据定义具有精确的姿态注释，可以在实际情况下准确地预测姿态。我们在具有精确姿态注释的真实数据集上测试了网络，并在AFLW、AFLW2000[35]和BIWI[6]数据集上展示了最先进的结果。此外，我们开始使用非常精确的方法来缩小差距，这些方法使用BIWI数据集上的深度信息。</p>
<p>我们认为，与“地标-位”方法相比，深度网络有很大的优势，例如:</p>
<p>•它们不依赖于:选择的头部模型，地标检测方法，用于对齐头部模型的点子集或对齐2D到3D点的优化方法。</p>
<p>•当地标检测方法失败时，它们总是输出一个姿态预测，而后一种方法则不是这样。</p>
<h2 id="3-2-多重损失方法"><a href="#3-2-多重损失方法" class="headerlink" title="3.2.多重损失方法"></a>3.2.多重损失方法</h2><p>所有先前使用卷积网络预测头部姿态的工作都直接使用均方误差损失回归所有三个欧拉角。我们注意到，这种方法在我们的大规模合成训练数据上并没有取得最好的结果。</p>
<p>我们建议使用三个单独的损失，每个角度一个。每个损失是两个组成部分的组合:一个binned姿势分类和回归组成部分。任何骨干网都可以使用，并增加三个全连接层来预测角度。这三个完全连接的层共享之前的卷积层网络。</p>
<p>这种方法背后的想法是，通过执行bin分类，我们使用非常稳定的softmax层和交叉熵，因此网络学习以稳健的方式预测姿态的邻域。通过三个交叉熵损失，每个欧拉角一个，我们有三个信号反向传播到网络中，这有助于学习。为了获得一个细粒度的预测，我们计算了装箱输出的每个输出角度的期望。详细的体系结构如图2所示。</p>
<p><img src="https://s2.loli.net/2022/06/30/O8jXesd7nWNuqBE.gif" alt="img"></p>
<p>图2</p>
<h2 id="3-3-综合扩展数据集训练"><a href="#3-3-综合扩展数据集训练" class="headerlink" title="3.3.综合扩展数据集训练"></a>3.3.综合扩展数据集训练</h2><p>我们遵循[2]的路径，利用综合扩展的数据训练他们的地标检测模型。他们训练的数据集之一是300W-LP数据集，这是一个流行的2D里程碑数据集的集合，这些数据集已经被分组和重新注释。人脸模型适合于每一张图像，图像被扭曲以改变人脸的偏航，这给我们提供了几个偏航角度的姿势。</p>
<p>姿势是准确的标记，因为我们有3D模型和6-D自由度的每个图像的脸。</p>
<p>在4.1节中，我们展示了通过仔细训练大量的合成数据，我们可以开始弥合与现有深度方法的差距，并可以通过细粒度的姿态注释在数据集上实现非常好的准确性。我们还将我们的方法与其他深度学习方法进行了对比，这些方法的作者已经在4.1节中使用的一些测试数据集上运行了。此外，在同一节中，我们测试了地标-位姿方法和其他类型的位姿估计方法，如3D模型拟合。</p>
<h1 id="4-实验结果"><a href="#4-实验结果" class="headerlink" title="4.实验结果"></a>4.实验结果</h1><p>我们在不同的姿态估计数据集以及流行的地标检测数据集上进行了实验，展示了我们提出的方法的整体性能。我们展示了多次损失的消融研究。此外，我们深入研究了地标姿态方法，并阐明了它们的鲁棒性。最后，我们提出的实验表明，在分辨率较低的情况下，即使地标探测器是最先进的，使用深度网络的整体姿态方法也优于地标到姿态方法。</p>
<h2 id="4-1-基于AFLW2000和BIWI数据集的细粒度姿态估计"><a href="#4-1-基于AFLW2000和BIWI数据集的细粒度姿态估计" class="headerlink" title="4.1. 基于AFLW2000和BIWI数据集的细粒度姿态估计"></a>4.1. 基于AFLW2000和BIWI数据集的细粒度姿态估计</h2><p>我们在AFLW2000和BIWI数据集上评估我们的方法，用于细粒度姿态估计任务。</p>
<p>  在AFLW2000和BIWI数据集上运行这两个地标识别器。AFLW2000图像很小，在脸部周围进行裁剪。对于BIWI，我们运行一个Faster R-CNN人脸检测器，训练于WIDER人脸数据集[32,10]，并部署在Docker容器中。为了保留头部的其余部分，我们在边框周围松散地剪裁脸部。我们还从AFLW2000的地面真实地标检索姿态。</p>
<p><img src="https://s2.loli.net/2022/06/30/VofEJgbyW52D7Yp.gif" alt="img"></p>
<p><img src="https://s2.loli.net/2022/06/30/sZCivXc3PRpF7N4.gif" alt="img"></p>
<p><img src="https://s2.loli.net/2022/06/30/DHRawu3SMAQpKj9.gif" alt="img"></p>
<p><img src="https://s2.loli.net/2022/06/30/iPvVRHgSeLW9rsq.gif" alt="img"></p>
<p><img src="https://s2.loli.net/2022/06/30/wxCcIpZXB96Soln.gif" alt="img"></p>
<p><img src="https://s2.loli.net/2022/06/30/XvZHkyCfG54RLtP.gif" alt="img"></p>
<p>  我们将我们的结果与最先进的RGBD方法进行比较。我们可以看到，我们提出的方法大大缩小了RGBD方法和ResNet50之间的差距。由于300W-LP数据集中缺乏大量极端基音的例子，基音估计仍然滞后。我们预计，当获得更多数据时，这一差距将会缩小。</p>
<h2 id="4-2-AFLW和AFW"><a href="#4-2-AFLW和AFW" class="headerlink" title="4.2.AFLW和AFW"></a>4.2.AFLW和AFW</h2><p>AFW是一个很受欢迎的数据集，也常用于测试地标检测，其中包含粗略的姿态标注。</p>
<p>利用AlexNet[13]的联合分类和回归损失，我们得到了25个epoch训练后相似的平均平均误差。我们将我们的结果与KEPLER[14]方法(使用改进的GoogleNet进行同时地标检测和姿态估计)和[19]方法(使用4层卷积网络)进行比较。MultiLoss ResNet50在AFLW测试集中使用Adam和4.1节中相同的学习参数进行了25个epoch的训练后，在所有角度上实现了比KEPLER更低的平均误差。</p>
<p>我们在AFW数据集上测试之前训练过的AlexNet和Multi-Loss ResNet50网络，并在图7中显示结果。与所有相关的工作一样，我们对偏航的结果进行了唯一的评估。我们限制我们的网络输出离散偏航在15度增量和显示精度在两个不同的偏航阈值。如果预测偏航的绝对误差小于或等于所提出的阈值，则可以正确分类。</p>
<p>所有比较方法采用相同的测试方案，数据直接来自相关论文。Hyperface[20]和All-In-One[21]都使用单一网络完成大量面部分析任务。Hyperface使用在ImageNet上预训练的AlexNet作为骨干，All-In-One使用在使用三重概率约束[25]的人脸识别任务上预训练的7层骨干卷积网络。</p>
<p>我们表明，通过在ImageNet上的预训练和在AFLW数据集上的微调，我们获得的准确性非常接近相关工作的最佳结果。我们不使用任何其他可能提高网络性能的监督信息，如2D地标注释。然而，我们确实在ResNet50中使用了一个更强大的骨干网。我们展示了同一网络在AFLW测试集和AFW上的性能。</p>
<h1 id="5-结论和未来工作"><a href="#5-结论和未来工作" class="headerlink" title="5.结论和未来工作"></a>5.结论和未来工作</h1><p>在这项工作中，我们表明，一个多重损失的深度网络可以直接，准确和稳健地预测头部旋转的图像强度。我们展示了这种网络优于使用最先进的地标检测方法的地标到姿态方法。本文研究了地标-姿态方法，以显示其对外部因素的依赖性。如图3所示，不同方法在低采样AFLW2000数据集上的平均平均误差，以确定方法对低分辨率图像的鲁棒性。</p>
<p>如头部模型和路标检测精度。</p>
<p>我们还表明，我们提出的方法可以推广跨数据集，它优于将头部姿态作为检测地标的子目标的网络。我们表明，在分辨率很低的情况下，地标到姿态是脆弱的，如果训练数据得到适当的增强，我们的方法对这些情况显示出鲁棒性。</p>
<p>对于极端姿势的合成数据生成似乎是提高所提方法性能的一种方法，对于更复杂的网络架构的研究可能会考虑到全身姿势等。</p>
<p><img src="https://s2.loli.net/2022/06/30/uNUTW5Vax9E7MCZ.gif" alt="img"></p>
<p>图3</p>
<p>参 考 文 献</p>
<p>[1] A. Bulat and G. Tzimiropoulos. Binarized convolutional</p>
<p>landmark localizers for human pose estimation and face</p>
<p>alignment with limited resources. In International Confer-</p>
<p>ence on Computer Vision, 2017. 5</p>
<p>[2] A. Bulat and G. Tzimiropoulos. How far are we from solv-</p>
<p>ing the 2d &amp; 3d face alignment problem? (and a dataset of</p>
<p>230,000 3d facial landmarks). In International Conference</p>
<p>on Computer Vision, 2017. 1, 2, 4, 5</p>
<p>[3] F.-J. Chang, A. T. Tran, T. Hassner, I. Masi, R. Nevatia, and</p>
<p>G. Medioni. Faceposenet: Making a case for landmark-free</p>
<p>face alignment. In Computer Vision Workshop (ICCVW),</p>
<p>2017 IEEE International Conference on, pages 1599–1608.</p>
<p>IEEE, 2017. 1, 2</p>
<p>[4] T. F. Cootes, G. J. Edwards, and C. J. Taylor. Active appear-</p>
<p>ance models. IEEE Transactions on Pattern Analysis and</p>
<p>Machine Intelligence, 23(6):681–685, jun 2001. 1</p>
<p>[5] J. G. X. Y . S. De and M. J. Kautz. Dynamic facial analysis:</p>
<p>From bayesian filtering to recurrent neural network. 2017. 2,</p>
<p>5</p>
<p>[6] G. Fanelli, M. Dantone, J. Gall, A. Fossati, and L. V an Gool.</p>
<p>Random forests for real time 3d face analysis. Int. J. Comput.</p>
<p>Vision, 101(3):437–458, February 2013. 3, 5</p>
<p>[7] R. Girshick, J. Donahue, T. Darrell, and J. Malik. Rich fea-</p>
<p>ture hierarchies for accurate object detection and semantic</p>
<p>segmentation. In Computer Vision and Pattern Recognition,</p>
<p>\2014. 2</p>
<p>[8] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learn-</p>
<p>ing for image recognition. arXiv preprint arXiv:1512.03385,</p>
<p>\2015. 5</p>
<p>[9] J. Huang, X. Shao, and H. Wechsler. Face pose discrimina-</p>
<p>tion using support vector machines (svm). In Pattern Recog-</p>
<p>nition, 1998. Proceedings. F ourteenth International Confer-</p>
<p>ence on, volume 1, pages 154–156. IEEE, 1998. 2</p>
<p>[10] H. Jiang and E. Learned-Miller. Face detection with the</p>
<p>faster r-cnn. In Automatic Face &amp; Gesture Recognition (FG</p>
<p>2017), 2017 12th IEEE International Conference on, pages</p>
<p>650–657. IEEE, 2017. 5</p>
<p>[11] V . Kazemi and J. Sullivan. One millisecond face alignment</p>
<p>with an ensemble of regression trees. In Proceedings of the</p>
<p>IEEE Conference on Computer Vision and Pattern Recogni-</p>
<p>tion, pages 1867–1874, 2014. 5</p>
<p>[12] D. Kingma and J. Ba. Adam: A method for stochastic opti-</p>
<p>mization. arXiv preprint arXiv:1412.6980, 2014. 5</p>
<p>[13] A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet</p>
<p>classification with deep convolutional neural networks. In</p>
<p>Advances in neural information processing systems, pages</p>
<p>1097–1105, 2012. 6</p>
<p>[14] A. Kumar, A. Alavi, and R. Chellappa. Kepler: Keypoint and</p>
<p>pose estimation of unconstrained faces by learning efficient</p>
<p>h-cnn regressors. In Automatic Face &amp; Gesture Recognition</p>
<p>(FG 2017), 2017 12th IEEE International Conference on,</p>
<p>pages 258–265. IEEE, 2017. 1, 2, 5, 6, 7, 8</p>
<p> [15] I. Matthews and S. Baker. Active Appearance Models Revis-</p>
<p>ited. International Journal of Computer Vision, 60(2):135–</p>
<p>164, 2004. 1</p>
<p>[16] A. Newell, K. Yang, and J. Deng. Stacked hourglass net-</p>
<p>works for human pose estimation. In European Conference</p>
<p>on Computer Vision, pages 483–499. Springer, 2016. 5</p>
<p>[17] J. Ng and S. Gong. Composite support vector machines for</p>
<p>detection of faces across views and pose estimation. Image</p>
<p>and Vision Computing, 20(5):359–368, 2002. 2</p>
<p>[18] E. Osuna, R. Freund, and F. Girosit. Training support vec-</p>
<p>tor machines: an application to face detection. In Computer</p>
<p>vision and pattern recognition, 1997. Proceedings., 1997</p>
<p>IEEE computer society conference on, pages 130–136. IEEE,</p>
<p>\1997. 2</p>
<p>[19] M. Patacchiola and A. Cangelosi. Head pose estimation in</p>
<p>the wild using convolutional neural networks and adaptive</p>
<p>gradient methods. Pattern Recognition, 2017. 1, 2, 6, 7</p>
<p>[20] R. Ranjan, V . M. Patel, and R. Chellappa. Hyperface: A deep</p>
<p>multi-task learning framework for face detection, landmark</p>
<p>localization, pose estimation, and gender recognition. arXiv</p>
<p>preprint arXiv:1603.01249, 2016. 1, 2, 6, 8</p>
<p>[21] R. Ranjan, S. Sankaranarayanan, C. D. Castillo, and R. Chel-</p>
<p>lappa. An all-in-one convolutional neural network for face</p>
<p>analysis. In Automatic Face &amp; Gesture Recognition (FG</p>
<p>2017), 2017 12th IEEE International Conference on, pages</p>
<p>17–24. IEEE, 2017. 1, 2, 6, 8</p>
<p>[22] S. Ren, K. He, R. Girshick, and J. Sun. Faster R-CNN: To-</p>
<p>wards real-time object detection with region proposal net-</p>
<p>works. In Advances in Neural Information Processing Sys-</p>
<p>tems (NIPS), 2015. 5</p>
<p>[23] H. A. Rowley, S. Baluja, and T. Kanade. Neural network-</p>
<p>based face detection. IEEE Transactions on pattern analysis</p>
<p>and machine intelligence, 20(1):23–38, 1998. 2</p>
<p>[24] N. Ruiz and J. M. Rehg. Dockerface: an easy to install and</p>
<p>use faster r-cnn face detector in a docker container. arXiv</p>
<p>preprint arXiv:1708.04370, 2017. 5</p>
<p>[25] S. Sankaranarayanan, A. Alavi, C. D. Castillo, and R. Chel-</p>
<p>lappa. Triplet probabilistic embedding for face verification</p>
<p>and clustering. In Biometrics Theory, Applications and Sys-</p>
<p>tems (BTAS), 2016 IEEE 8th International Conference on,</p>
<p>pages 1–8. IEEE, 2016. 6</p>
<p>[26] J. M. Saragih, S. Lucey, and J. F. Cohn. Deformable model</p>
<p>fitting by regularized landmark mean-shift. International</p>
<p>Journal of Computer Vision, 91(2):200–215, 2011. 1</p>
<p>[27] J. Sherrah, S. Gong, and E.-J. Ong. Understanding pose dis-</p>
<p>crimination in similarity space. In BMVC, pages 1–10, 1999.</p>
<p>2</p>
<p>[28] J. Sherrah, S. Gong, and E.-J. Ong. Face distributions in</p>
<p>similarity space under varying head pose. Image and Vision</p>
<p>Computing, 19(12):807–819, 2001. 2</p>
<p>[29] Xiangxin Zhu and D. Ramanan. Face detection, pose estima-</p>
<p>tion, and landmark localization in the wild. In Proceedings</p>
<p>IEEE Conference on Computer Vision and Pattern Recogni-</p>
<p>tion (CVPR), pages 2879–2886, jun 2012. 1</p>
<p>[30] X. Xiong and F. De la Torre. Supervised descent method</p>
<p>and its applications to face alignment. In Proceedings of the</p>
<p>IEEE Conference on Computer Vision and Pattern Recogni-</p>
<p>tion (CVPR), pages 532–539, 2013. 1</p>
<p>[31] H. Yang, W. Mou, Y . Zhang, I. Patras, H. Gunes, and</p>
<p>P . Robinson. Face alignment assisted by head pose estima-</p>
<p>tion. In Proceedings of the British Machine Vision Confer-</p>
<p>ence (BMVC), 2015. 1</p>
<p>[32] S. Yang, P . Luo, C. C. Loy, and X. Tang. Wider face: A</p>
<p>face detection benchmark. In IEEE Conference on Computer</p>
<p>Vision and Pattern Recognition (CVPR), 2016. 5</p>
<p>[33] Y . Y u, K. A. F. Mora, and J. M. Odobez. Robust and accu-</p>
<p>rate 3d head pose estimation through 3dmm and online head</p>
<p>model reconstruction. In Automatic Face &amp; Gesture Recog-</p>
<p>nition (FG 2017), 2017 12th IEEE International Conference</p>
<p>on, pages 711–718. IEEE, 2017. 5</p>
<p>[34] Z. Zhang, Y . Hu, M. Liu, and T. Huang. Head pose</p>
<p>estimation in seminar room using multi view face detec-</p>
<p>tors. In International Evaluation Workshop on Classifica-</p>
<p>tion of Events, Activities and Relationships, pages 299–304.</p>
<p>Springer, 2006. 2</p>
<p>[35] X. Zhu, Z. Lei, X. Liu, H. Shi, and S. Z. Li. Face alignment</p>
<p>across large poses: A 3d solution. In Proceedings of the</p>
<p>IEEE Conference on Computer Vision and Pattern Recogni-</p>
<p>tion, pages 146–155, 2016. 1, 2, 3, 5</p>
<p>[36] X. Zhu and D. Ramanan. Face detection, pose estimation,</p>
<p>and landmark localization in the wild. In Computer Vision</p>
<p>and Pattern Recognition (CVPR), 2012 IEEE Conference on,</p>
<p>pages 2879–2886. IEEE, 2012. 8</p>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">DanielWang1314</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="http://DanielWang1314.github.io/2022/06/30/xin-xi-yu-nei-rong-an-quan-xue-zhu-lun-wen/">http://DanielWang1314.github.io/2022/06/30/xin-xi-yu-nei-rong-an-quan-xue-zhu-lun-wen/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">DanielWang1314</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            <span class="chip bg-color">无标签</span>
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="far fa-dot-circle"></i>&nbsp;本篇
            </div>
            <div class="card">
                <a href="/2022/06/30/xin-xi-yu-nei-rong-an-quan-xue-zhu-lun-wen/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/0.jpg" class="responsive-img" alt="">
                        
                        <span class="card-title"></span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2022-06-30
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-user fa-fw"></i>
                            DanielWang1314
                            
                        </span>
                    </div>
                </div>

                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2022/06/30/danielwang1314-readme/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/0.jpg" class="responsive-img" alt="">
                        
                        <span class="card-title"></span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2022-06-30
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-user fa-fw"></i>
                            DanielWang1314
                            
                        </span>
                    </div>
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>


  <!-- 是否加载使用自带的 prismjs. -->
  <script type="text/javascript" src="/libs/prism/prism.min.js"></script>


<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2019-2022</span>
            
            <a href="/about" target="_blank">DanielWang1314</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/DanielWang1314520" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:danielwang1314@foxmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=1840674998" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 1840674998" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>







    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    

    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
